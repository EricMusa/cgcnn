{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document demonstrates the making, training, saving, loading, and usage of a sklearn-compliant CGCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "sys.path.insert(0,'/home/zulissi/software/adamwr')\n",
    "import numpy as np\n",
    "import cgcnn\n",
    "#Select which GPU to use if necessary\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset as mongo docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "#Load a selection of documents\n",
    "docs = pickle.load(open('/home/zulissi/software/cgcnn_sklearn/CO_docs.pkl','rb'))\n",
    "random.seed(42)\n",
    "random.shuffle(docs)\n",
    "docs = [doc for doc in docs if -3<doc['energy']<1.0]\n",
    "docs = docs[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the size of the features from the data transformer, to be used in setting up the net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:19<00:00,  3.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mongo\n",
    "from cgcnn.data import StructureData, ListDataset, StructureDataTransformer\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "SDT = StructureDataTransformer(atom_init_loc='/home/zulissi/software/cgcnn_sklearn/atom_init.json',\n",
    "                              max_num_nbr=12,\n",
    "                               step=0.2,\n",
    "                              radius=1,\n",
    "                              use_tag=True,\n",
    "                              use_fixed_info=False,\n",
    "                              use_distance=True)\n",
    "\n",
    "SDT_out = SDT.transform(docs)\n",
    "\n",
    "structures = SDT_out[0]\n",
    "\n",
    "#Settings necessary to build the model (since they are size of vectors as inputs)\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "import multiprocess as mp\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "SDT_out = SDT.transform(docs)\n",
    "\n",
    "with mp.Pool(4) as pool:\n",
    "    SDT_list = list(tqdm.tqdm(pool.imap(lambda x: SDT_out[x],range(len(SDT_out)),chunksize=40),total=len(SDT_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('distance_all_docs.pkl','wb') as fhandle:\n",
    "    pickle.dump(SDT_list,fhandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGCNN model with skorch to make it sklearn compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from skorch.callbacks import Checkpoint, LoadInitState #needs skorch 0.4.0, conda-forge version at 0.3.0 doesn't cut it\n",
    "from cgcnn.data import collate_pool\n",
    "from skorch import NeuralNetRegressor\n",
    "from cgcnn.model import CrystalGraphConvNet\n",
    "import torch\n",
    "from cgcnn.data import MergeDataset\n",
    "import skorch.callbacks.base\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "#Make a checkpoint to save parameters every time there is a new best for validation lost\n",
    "cp = Checkpoint(monitor='valid_loss_best',fn_prefix='valid_best_')\n",
    "\n",
    "#Callback to load the checkpoint with the best validation loss at the end of training\n",
    "class train_end_load_best_valid_loss(skorch.callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('valid_best_params.pt')\n",
    "        \n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example converting all the documents up front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the target list\n",
    "target_list = np.array([doc['energy'] for doc in docs]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SDT_training, SDT_test, target_training, target_test = train_test_split(SDT_list, target_list, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.dataset import CVSplit\n",
    "from skorch.callbacks.lr_scheduler import WarmRestartLR, LRScheduler\n",
    "from adamw import AdamW\n",
    "from cosine_scheduler import CosineLRWithRestarts\n",
    "\n",
    "train_test_splitter = ShuffleSplit(test_size=0.25, random_state=42)\n",
    "\n",
    "# warm restart scheduling from https://arxiv.org/pdf/1711.05101.pdf\n",
    "LR_schedule = LRScheduler(CosineLRWithRestarts, batch_size=214, epoch_size=len(SDT_training), restart_period=10, t_mult=1.2)\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "    module__nbr_fea_len = nbr_fea_len,\n",
    "    batch_size=214,\n",
    "    module__classification=False,\n",
    "    lr=0.0056,\n",
    "    max_epochs=100, #188\n",
    "    module__atom_fea_len=46,\n",
    "    module__h_fea_len=1,\n",
    "    module__n_conv=8,\n",
    "    module__n_h=1,\n",
    "    module__visualization=True, #Switch to per-atom energy mode\n",
    "    optimizer=AdamW,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__collate_fn = collate_pool,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn = collate_pool,\n",
    "    device=device,\n",
    "#     criterion=torch.nn.MSELoss,\n",
    "    criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "    train_split = CVSplit(cv=train_test_splitter),\n",
    "    callbacks=[cp, load_best_valid_loss, LR_schedule]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: atom_fea_len, classification, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len, visualization.\n",
      "Re-initializing optimizer because the following parameters were re-set: .\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6824\u001b[0m        \u001b[32m0.6249\u001b[0m     +  0.9599\n",
      "      2        \u001b[36m0.4913\u001b[0m        \u001b[32m0.5982\u001b[0m     +  0.8826\n",
      "      3        \u001b[36m0.3927\u001b[0m        \u001b[32m0.5843\u001b[0m     +  0.8825\n",
      "      4        \u001b[36m0.3489\u001b[0m        \u001b[32m0.5739\u001b[0m     +  0.8861\n",
      "      5        \u001b[36m0.3427\u001b[0m        \u001b[32m0.5609\u001b[0m     +  0.8865\n",
      "      6        \u001b[36m0.3188\u001b[0m        \u001b[32m0.5418\u001b[0m     +  0.8874\n",
      "      7        \u001b[36m0.3116\u001b[0m        \u001b[32m0.5172\u001b[0m     +  0.8863\n",
      "      8        \u001b[36m0.3003\u001b[0m        \u001b[32m0.4936\u001b[0m     +  0.8857\n",
      "      9        \u001b[36m0.2954\u001b[0m        \u001b[32m0.4687\u001b[0m     +  0.8880\n",
      "     10        \u001b[36m0.2931\u001b[0m        \u001b[32m0.4464\u001b[0m     +  0.8865\n",
      "     11        0.3008        \u001b[32m0.4133\u001b[0m     +  0.8860\n",
      "     12        \u001b[36m0.2909\u001b[0m        \u001b[32m0.3968\u001b[0m     +  0.8860\n",
      "     13        \u001b[36m0.2770\u001b[0m        \u001b[32m0.3733\u001b[0m     +  0.8861\n",
      "     14        \u001b[36m0.2731\u001b[0m        0.3754        0.8859\n",
      "     15        \u001b[36m0.2569\u001b[0m        0.3782        0.8860\n",
      "     16        \u001b[36m0.2335\u001b[0m        \u001b[32m0.3388\u001b[0m     +  0.8864\n",
      "     17        \u001b[36m0.2256\u001b[0m        0.3686        0.8861\n",
      "     18        \u001b[36m0.2108\u001b[0m        0.3461        0.8857\n",
      "     19        \u001b[36m0.1972\u001b[0m        0.3420        0.8865\n",
      "     20        \u001b[36m0.1929\u001b[0m        \u001b[32m0.3252\u001b[0m     +  0.8855\n",
      "     21        \u001b[36m0.1880\u001b[0m        \u001b[32m0.3168\u001b[0m     +  0.8862\n",
      "     22        \u001b[36m0.1858\u001b[0m        \u001b[32m0.3151\u001b[0m     +  0.8861\n",
      "     23        0.2482        0.7058        0.8859\n",
      "     24        0.2381        0.3771        0.8866\n",
      "     25        0.2349        0.3248        0.8855\n",
      "     26        0.2373        0.3828        0.8857\n",
      "     27        0.2093        0.3152        0.8857\n",
      "     28        0.2126        0.3237        0.8859\n",
      "     29        0.1901        \u001b[32m0.3113\u001b[0m     +  0.8857\n",
      "     30        \u001b[36m0.1671\u001b[0m        0.3117        0.8860\n",
      "     31        \u001b[36m0.1605\u001b[0m        \u001b[32m0.3067\u001b[0m     +  0.8861\n",
      "     32        \u001b[36m0.1494\u001b[0m        \u001b[32m0.2933\u001b[0m     +  0.8856\n",
      "     33        \u001b[36m0.1398\u001b[0m        \u001b[32m0.2864\u001b[0m     +  0.8862\n",
      "     34        \u001b[36m0.1337\u001b[0m        0.2880        0.8852\n",
      "     35        \u001b[36m0.1309\u001b[0m        0.2865        0.8861\n",
      "     36        \u001b[36m0.1283\u001b[0m        \u001b[32m0.2849\u001b[0m     +  0.8857\n",
      "     37        \u001b[36m0.1278\u001b[0m        \u001b[32m0.2841\u001b[0m     +  0.8852\n",
      "     38        0.1970        0.4023        0.8859\n",
      "     39        0.2254        0.3296        0.8859\n",
      "     40        0.2200        0.3781        0.8856\n",
      "     41        0.2173        0.2934        0.8860\n",
      "     42        0.1930        0.3081        0.8859\n",
      "     43        0.1699        0.3297        0.8869\n",
      "     44        0.1618        0.3158        0.8862\n",
      "     45        0.1459        0.3068        0.8863\n",
      "     46        0.1369        0.3062        0.8855\n",
      "     47        \u001b[36m0.1190\u001b[0m        0.3186        0.8865\n",
      "     48        0.1202        0.2971        0.8853\n",
      "     49        \u001b[36m0.1065\u001b[0m        0.2943        0.8859\n",
      "     50        \u001b[36m0.1005\u001b[0m        \u001b[32m0.2816\u001b[0m     +  0.8863\n",
      "     51        \u001b[36m0.0959\u001b[0m        0.2834        0.8860\n",
      "     52        \u001b[36m0.0913\u001b[0m        0.2849        0.8860\n",
      "     53        \u001b[36m0.0888\u001b[0m        0.2840        0.8861\n",
      "     54        \u001b[36m0.0874\u001b[0m        0.2832        0.8856\n",
      "     55        \u001b[36m0.0872\u001b[0m        0.2828        0.8852\n",
      "     56        0.1541        0.3329        0.8879\n",
      "     57        0.1784        0.3100        0.8864\n",
      "     58        0.1637        0.3101        0.8862\n",
      "     59        0.1502        0.3976        0.8891\n",
      "     60        0.1389        0.3238        0.8892\n",
      "     61        0.1279        0.3089        0.8901\n",
      "     62        0.1243        0.2994        0.8897\n",
      "     63        0.1275        0.2968        0.8887\n",
      "     64        0.1177        0.2896        0.8892\n",
      "     65        0.1103        0.2863        0.8891\n",
      "     66        0.0993        0.2822        0.8892\n",
      "     67        \u001b[36m0.0872\u001b[0m        \u001b[32m0.2747\u001b[0m     +  0.8890\n",
      "     68        \u001b[36m0.0849\u001b[0m        0.2817        0.8891\n",
      "     69        \u001b[36m0.0772\u001b[0m        0.2778        0.8888\n",
      "     70        \u001b[36m0.0721\u001b[0m        0.2791        0.8896\n",
      "     71        \u001b[36m0.0671\u001b[0m        0.2786        0.8893\n",
      "     72        \u001b[36m0.0624\u001b[0m        0.2764        0.8898\n",
      "     73        \u001b[36m0.0586\u001b[0m        0.2793        0.8897\n",
      "     74        \u001b[36m0.0558\u001b[0m        0.2800        0.8900\n",
      "     75        \u001b[36m0.0544\u001b[0m        0.2799        0.8960\n",
      "     76        \u001b[36m0.0538\u001b[0m        0.2798        0.8894\n",
      "     77        0.1369        0.3642        0.8891\n",
      "     78        0.1958        0.3401        0.8892\n",
      "     79        0.1926        0.3163        0.8902\n",
      "     80        0.1743        0.3089        0.8890\n",
      "     81        0.1682        0.3240        0.8895\n",
      "     82        0.1437        0.3297        0.8886\n",
      "     83        0.1326        0.3151        0.8887\n",
      "     84        0.1128        0.2919        0.8894\n",
      "     85        0.1086        0.2901        0.8891\n",
      "     86        0.0942        \u001b[32m0.2744\u001b[0m     +  0.8890\n",
      "     87        0.0871        0.3064        0.8895\n",
      "     88        0.0874        0.2794        0.8890\n",
      "     89        0.0766        0.2767        0.8894\n",
      "     90        0.0696        0.2969        0.8888\n",
      "     91        0.0665        0.2957        0.8888\n",
      "     92        0.0663        0.2968        0.8887\n",
      "     93        0.0586        0.2790        0.8926\n",
      "     94        0.0543        0.2745        0.8935\n",
      "     95        \u001b[36m0.0508\u001b[0m        0.2745        0.8932\n",
      "     96        \u001b[36m0.0470\u001b[0m        0.2751        0.8922\n",
      "     97        \u001b[36m0.0440\u001b[0m        0.2748        0.8927\n",
      "     98        \u001b[36m0.0404\u001b[0m        0.2756        0.8939\n",
      "     99        \u001b[36m0.0385\u001b[0m        0.2756        0.8928\n",
      "    100        \u001b[36m0.0376\u001b[0m        0.2753        0.8922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=CrystalGraphConvNet(\n",
       "    (embedding): Linear(in_features=99, out_features=46, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (4): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (5): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (6): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (7): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (conv_to_fc): Linear(in_features=1, out_features=1, bias=True)\n",
       "    (visualization_layer): Linear(in_features=46, out_features=1, bias=True)\n",
       "    (conv_to_fc_softplus): LeakyReLU(negative_slope=0.01)\n",
       "    (fc_out): Linear(in_features=1, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.fit(SDT_training,target_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a hook to save the per-atom visualization each time the net is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f76e1e3ecc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "net.module_.visualization_layer.register_forward_hook(get_activation('visualization_layer'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save 5 atoms objects with the calculated per-atom energy as the \"charge\" attribute.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1073901300000042\n",
      "-0.01227288999998244\n",
      "-0.2209785799999846\n",
      "-0.3102291400000379\n",
      "-0.02101047999999217\n",
      "-0.4718952000000112\n",
      "-0.7153526599999989\n",
      "-1.4915358300000232\n",
      "0.36590288999998144\n",
      "-1.950037039999975\n",
      "-0.06121053999999582\n",
      "-0.7279071600000062\n",
      "-0.2920729799999915\n",
      "-0.151564590000012\n",
      "0.227957599999991\n",
      "-1.5148751800000095\n",
      "-0.6102481800000046\n",
      "-1.089113139999986\n",
      "-0.1325224099999982\n",
      "-1.4740079699999935\n"
     ]
    }
   ],
   "source": [
    "index=0\n",
    "for sdt,doc in zip(SDT_list[0:20],docs[0:20]):\n",
    "    net.predict([sdt])\n",
    "    energies = np.array(activation['visualization_layer']).reshape((-1))\n",
    "    atoms = mongo.make_atoms_from_doc(doc)\n",
    "    print(doc['results']['energy'])\n",
    "    #energies=energies*(1-atoms.get_tags())+atoms.get_tags()*np.mean(energies)\n",
    "    atoms.set_initial_charges(energies)\n",
    "    atoms.write('%d.traj'%(index))\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7427],\n",
       "        [-1.1437],\n",
       "        [-1.5398],\n",
       "        [-1.3790],\n",
       "        [-1.4278],\n",
       "        [-1.7802],\n",
       "        [-1.4174],\n",
       "        [-1.5122],\n",
       "        [-1.4333],\n",
       "        [-0.8792],\n",
       "        [-1.0983],\n",
       "        [-1.4074],\n",
       "        [-1.5057],\n",
       "        [-1.8026],\n",
       "        [-2.1501],\n",
       "        [-2.4727],\n",
       "        [-2.4548],\n",
       "        [-2.1757],\n",
       "        [-4.5324],\n",
       "        [-2.0303],\n",
       "        [-1.5243],\n",
       "        [-1.2144],\n",
       "        [-1.4278],\n",
       "        [-1.7801],\n",
       "        [-1.4174],\n",
       "        [-1.5117],\n",
       "        [-1.4540],\n",
       "        [-0.8784],\n",
       "        [-1.0666],\n",
       "        [-1.4035],\n",
       "        [-1.5058],\n",
       "        [-1.6550],\n",
       "        [-1.8995],\n",
       "        [-2.4358],\n",
       "        [-2.3782],\n",
       "        [-2.1807],\n",
       "        [-5.0775],\n",
       "        [-2.5906]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation['visualization_layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dsfhjjkgh32515' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1e36f87c6e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdsfhjjkgh32515\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dsfhjjkgh32515' is not defined"
     ]
    }
   ],
   "source": [
    "dsfhjjkgh32515"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
